# Agentic AR – Irish Object Lens (Streamlit)

This prototype turns a Streamlit app into an "agentic augmented reality" lens:
you open it on an iPhone (or any device with a camera), give camera permission,
and it draws small squares (bounding boxes) around detected objects with an
intelligent pop-up caption above them.

The caption is generated by an agentic reasoning layer using GPT‑4o‑mini
(designed for short, functional explanations grounded in Irish / farm / daily
life context).

---

## 1. Features

- Live camera feed via `streamlit-webrtc`
- YOLO-based object detection (via `ultralytics`)
- Agentic reasoner using OpenAI GPT‑4o‑mini (optional toggle)
- Spectre-style dark neon UI skin
- Experimental WebAR scaffold using A‑Frame (optional)

---

## 2. File Structure

```text
agentic_ar_streamlit/
  app.py                     # Main Streamlit app
  backend/
    __init__.py
    detector.py              # YOLO-based object detection wrapper
    agentic_reasoner.py      # GPT-4o-mini based explanation engine
  ui/
    spectre_theme.css        # Spectre neon HUD styling
  web_ar/
    index.html               # A-Frame-based placeholder for true WebAR
    script.js                # Future bridge to backend
    neon_hud.css             # Fullscreen WebAR styling
  requirements.txt
  README.md
```

---

## 3. Installation

```bash
cd agentic_ar_streamlit
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

You also need to:

1. Download a YOLOv8 model (the default `yolov8n.pt` will be auto-downloaded by `ultralytics` on first run).
2. Set your OpenAI API key:

```bash
export OPENAI_API_KEY="sk-..."   # Windows: setx OPENAI_API_KEY "sk-..."
```

---

## 4. Running the App

```bash
streamlit run app.py
```

On your iPhone:

1. Make sure both phone and computer are on the **same Wi‑Fi network**.
2. In a browser on the phone (Safari works best), go to:

   ```text
   http://<your-computer-LAN-ip>:8501
   ```

3. Grant **camera access** when prompted.
4. Toggle **"Enable Agentic Reasoner (GPT‑4o-mini)"** in the sidebar if you
   want pop-up explanations (this will call the OpenAI API).

---

## 5. How It Works (Conceptual)

1. `streamlit-webrtc` captures frames from the camera.
2. `backend.detector.Detector.detect_single()` runs YOLO on each processed frame
   to pick the most confident detection.
3. The bounding box and label are drawn on the frame using OpenCV.
4. If the reasoner is enabled, `AgenticReasoner.explain(label)` uses GPT‑4o‑mini
   to generate a concise, functional description (e.g., *"A tractor used to
   pull agricultural machinery across fields."*).
5. The app overlays this caption in a small floating rectangle above the object.

This gives you a **2D AR-style overlay** directly inside Streamlit, compatible
with iPhone browsers and laptops, without needing native ARKit.

---

## 6. WebAR Scaffold (Optional)

The `web_ar/` folder contains a minimal A‑Frame scene with a static holographic
tag. It is a **prototype entry point** for future work where you may:

- Capture camera frames in JavaScript;
- Send them to a FastAPI / Streamlit backend;
- Receive detection & explanation;
- Update `a-text` entities to show holographic labels in 3D.

You can serve `web_ar/index.html` separately (e.g. with a tiny HTTP server) or
embed it in Streamlit via `st.components.v1.html`.

---

## 7. Customisation Ideas

- Train / plug in a **farm-specific YOLO model**: cows, silos, parlours, sheds,
  slurry tanks, grass quality proxies, etc.
- Extend `AgenticReasoner` to:
  - Pull LPIS / CORINE attributes for geo-tagged objects;
  - Explain CAP Pillar I & II relevance;
  - Provide quick risk / safety tips (e.g., machinery hazards).
- Add a right-side **"Object Intelligence Panel"** summarising:
  - Object type, function, risk level;
  - Sustainability link (emissions, input use);
  - Maintenance hints.

This turns the prototype into a **Spectre Farm Intelligence Lens**.

---

## 8. Notes

- The current implementation processes every N‑th frame to control CPU & API
  usage. Tune `Processing FPS` in the sidebar.
- If `ultralytics` or `openai` are not installed, the app gracefully falls back
  by disabling detections or explanations.
- For production, you should:
  - Add error logging;
  - Use environment-based configuration;
  - Put rate limits on the OpenAI calls.

---

Happy building. This is a starting block – modify, extend, and plug into your
larger Spectre decision-intelligence ecosystem.
